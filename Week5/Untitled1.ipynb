{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SzMLtVsNJ4S",
        "colab_type": "code",
        "outputId": "eeb6b821-eaee-4ff5-fd68-b1e942a1d4c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip uninstall tensorflow"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WxAW_ZvNTr2",
        "colab_type": "code",
        "outputId": "8860e6cb-e902-4305-bbdc-9ca2b1711a40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        }
      },
      "source": [
        "!pip install tensorflow==2.0.0-beta1"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0-beta1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/6c/2c9a5c4d095c63c2fb37d20def0e4f92685f7aee9243d6aae25862694fd1/tensorflow-2.0.0b1-cp36-cp36m-manylinux1_x86_64.whl (87.9MB)\n",
            "\u001b[K     |████████████████████████████████| 87.9MB 81kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.8.0)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/dd/99c47dd007dcf10d63fd895611b063732646f23059c618a373e85019eb0e/tf_estimator_nightly-1.14.0.dev2019060501-py2.py3-none-any.whl (496kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 40.4MB/s \n",
            "\u001b[?25hCollecting tb-nightly<1.14.0a20190604,>=1.14.0a20190603\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/96/571b875cd81dda9d5dfa1422a4f9d749e67c0a8d4f4f0b33a4e5f5f35e27/tb_nightly-1.14.0a20190603-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 38.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.1.7)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.0.8)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.11.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.33.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta1) (3.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (0.16.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (41.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta1) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-beta1) (2.8.0)\n",
            "Installing collected packages: tf-estimator-nightly, tb-nightly, tensorflow\n",
            "Successfully installed tb-nightly-1.14.0a20190603 tensorflow-2.0.0b1 tf-estimator-nightly-1.14.0.dev2019060501\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QB8V9fzhNWzY",
        "colab_type": "text"
      },
      "source": [
        "## Part 1. Preparation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMORFYeBNaoz",
        "colab_type": "code",
        "outputId": "1281d25c-fbe0-467e-88d7-cad32f30956a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "import numpy as np\n",
        "import random, multiprocessing\n",
        "from datetime import datetime\n",
        "import nltk\n",
        "from nltk.corpus import brown\n",
        "from gensim.models import Word2Vec\n",
        "import tensorflow as tf\n",
        "from collections import Counter\n",
        "from itertools import chain\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2.0.0-beta1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JldfPnZ9NwSp",
        "colab_type": "code",
        "outputId": "82884cd2-3d76-40f5-e295-2ecb50e79bc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "nltk.download('brown')\n",
        "nltk.download('universal_tagset')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRApMpLkNl9j",
        "colab_type": "text"
      },
      "source": [
        "## Part 2. Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPiQ7pntODd0",
        "colab_type": "text"
      },
      "source": [
        "### 2.1 Discover Details of the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTQ8OUDCNleZ",
        "colab_type": "code",
        "outputId": "b41bf25a-0904-4347-c988-86ceefe37337",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "brown.categories()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['adventure',\n",
              " 'belles_lettres',\n",
              " 'editorial',\n",
              " 'fiction',\n",
              " 'government',\n",
              " 'hobbies',\n",
              " 'humor',\n",
              " 'learned',\n",
              " 'lore',\n",
              " 'mystery',\n",
              " 'news',\n",
              " 'religion',\n",
              " 'reviews',\n",
              " 'romance',\n",
              " 'science_fiction']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJg0pIKmONHf",
        "colab_type": "code",
        "outputId": "e77b63ef-2f55-48be-cdb1-6a5d366f7a49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(brown.words()))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1161192\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muRyhdPJOP6x",
        "colab_type": "code",
        "outputId": "1ccee76b-41e2-4589-d926-22237529a620",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(brown.fileids()))\n",
        "# There are only 500 documents. \n",
        "# So I have no idea why you set the limit of documentation size as 20000."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CO0QX-nGusG",
        "colab_type": "text"
      },
      "source": [
        "### 2.2 Hyper-parameter Preset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKqfNOzjGsgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMB_DIM = 300\n",
        "w2v = Word2Vec(brown.sents(), size = EMB_DIM, window=5, min_count=5, negative=15,\n",
        "               iter=10, workers=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvNuQi0HKydg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "93b23ba2-6649-419e-8993-5f1580d688e0"
      },
      "source": [
        "word_vectors = w2v.wv # get trained embeddings\n",
        "result = word_vectors.most_similar(positive = ['child'], negative = ['person'])\n",
        "print(\"Most similar to 'child' but dissimilar to 'person': \\n\", result[:3])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most similar to 'child' but dissimilar to 'person': \n",
            " [('voice', 0.36667150259017944), ('smile', 0.3282575011253357), ('Pamela', 0.326852411031723)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAcxpi-fPOdn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "UNK_INDEX = 0\n",
        "UNK_TOKEN = \"UNK\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9csnX3OPoZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HIDDEN_SIZE = 50\n",
        "BATCH_SIZE = 128\n",
        "MINI_BATCH_SIZE = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIhiWtbFOl6l",
        "colab_type": "text"
      },
      "source": [
        "### 2.3 Drop the common words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXDADcx-bt0Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words=set(stopwords.words(\"english\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBZPuE1hPfRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "source_list = brown.words()\n",
        "counts = Counter(chain(*map(set, source_list)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ6Th1DlRYd-",
        "colab_type": "code",
        "outputId": "125d8572-4a69-4ccf-b224-88fa59eafa6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tags = [tag for (word, tag) in brown.tagged_words()]\n",
        "print(len(set(tags)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "472\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBxiJjvZbIlq",
        "colab_type": "code",
        "outputId": "f7c5e1e1-7528-4deb-a726-eabd3054b778",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(tags[:20])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['AT', 'NP-TL', 'NN-TL', 'JJ-TL', 'NN-TL', 'VBD', 'NR', 'AT', 'NN', 'IN', 'NP$', 'JJ', 'NN', 'NN', 'VBD', '``', 'AT', 'NN', \"''\", 'CS']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_fq6btGa1OZ",
        "colab_type": "code",
        "outputId": "e1de9c4b-3ce0-4795-8a56-17ad4d9c96d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "brown.tagged_words()[:30]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'AT'),\n",
              " ('Fulton', 'NP-TL'),\n",
              " ('County', 'NN-TL'),\n",
              " ('Grand', 'JJ-TL'),\n",
              " ('Jury', 'NN-TL'),\n",
              " ('said', 'VBD'),\n",
              " ('Friday', 'NR'),\n",
              " ('an', 'AT'),\n",
              " ('investigation', 'NN'),\n",
              " ('of', 'IN'),\n",
              " (\"Atlanta's\", 'NP$'),\n",
              " ('recent', 'JJ'),\n",
              " ('primary', 'NN'),\n",
              " ('election', 'NN'),\n",
              " ('produced', 'VBD'),\n",
              " ('``', '``'),\n",
              " ('no', 'AT'),\n",
              " ('evidence', 'NN'),\n",
              " (\"''\", \"''\"),\n",
              " ('that', 'CS'),\n",
              " ('any', 'DTI'),\n",
              " ('irregularities', 'NNS'),\n",
              " ('took', 'VBD'),\n",
              " ('place', 'NN'),\n",
              " ('.', '.'),\n",
              " ('The', 'AT'),\n",
              " ('jury', 'NN'),\n",
              " ('further', 'RBR'),\n",
              " ('said', 'VBD'),\n",
              " ('in', 'IN')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10rF3TAOQsCL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in source_list:\n",
        "  print(i.ca)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE_ucct9VO-d",
        "colab_type": "code",
        "outputId": "a5d695be-0e39-4458-ea64-4c0f3977d341",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "brown.tagged_words(tagset='universal')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'DET'), ('Fulton', 'NOUN'), ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_nOOLzoVwve",
        "colab_type": "code",
        "outputId": "be993011-8014-4ce6-80e3-ccd0c6a0dd10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(brown.tagged_words(tagset='universal')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1161192\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppjXw3tPQPQg",
        "colab_type": "code",
        "outputId": "a0309d88-38e2-4268-b119-4136c741f5c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(source_list))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1161192\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVnt6AIbOlCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for genre in brown.categories():\n",
        "  [i for i in brown.words(categories=genre) if counts[i]==1]\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK1LoBK1AMgT",
        "colab_type": "text"
      },
      "source": [
        "### 2.4 Split Train and Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qj2vHzvAoql",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "brown_tagged_sents = brown.tagged_sents()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ii1rUC43ChsV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tag_words = brown.tagged_words()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SntP6ZySDJ9T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "59149874-f2da-4537-9a1c-d0685b142c57"
      },
      "source": [
        "print(tag_words[:10])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSSwjT6sDOHZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "58dcb6e2-1c7b-4def-bad1-d226735b08b5"
      },
      "source": [
        "for item in tag_words[:10]:\n",
        "  print(item[1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AT\n",
            "NP-TL\n",
            "NN-TL\n",
            "JJ-TL\n",
            "NN-TL\n",
            "VBD\n",
            "NR\n",
            "AT\n",
            "NN\n",
            "IN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khzlXqOtApyI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "4b7ab9cb-80e7-4c7f-d23c-3bcb4cddb80a"
      },
      "source": [
        "bigram_tagger = nltk.bigrams(tag_words)\n",
        "tags = [b[1] for (a,b) in  bigram_tagger]\n",
        "fd = nltk.FreqDist(tags)\n",
        "fd.tabulate()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         NN          IN          AT          JJ           .           ,         NNS          CC          RB          NP          VB         VBN         VBD          CS         PPS         VBG         PP$          TO        PPSS          CD       NN-TL          MD         PPO         BEZ        BEDZ          AP          DT          ``          ''          QL         VBZ          BE          RP         WDT         HVD           *         WRB         BER       JJ-TL       NP-TL          HV         WPS          --         BED         ABN         DTI          PN         NP$         BEN         DTS         HVZ           )           (      NNS-TL          EX         JJR          OD          NR           :         NN$       IN-TL       NN-HL          DO         NPS         PPL         RBR         DOD         JJT       CD-TL         MD*       AT-TL         ABX         BEG      NNS-HL          UH        .-HL      VBN-TL       NP-HL       IN-HL         DO*     PPSS+MD         DOZ       CD-HL     PPS+BEZ        DOD*       JJ-HL      NN$-TL         JJS         ABL        PPLS       AT-HL           '       NR-TL       CC-TL       FW-NN         HVG         WPO    PPSS+BER    PPSS+BEM         QLP        NNS$         WP$     PPSS+HV         HVN         BEM       OD-TL        )-HL      DT+BEZ         WQL        ,-HL    FW-NN-TL        PP$$        (-HL         NIL       BEDZ*      VBG-HL      PPS+MD      NP$-TL        :-HL      VBN-HL      VBG-TL    NN-TL-HL       VB-HL       CC-HL       NN-NC        BEZ*      EX+BEZ         DTX         RBT        HVD*       VB-TL        DOZ*         PN$       FW-IN    PPSS+HVD      FW-NNS     PPS+HVD     NNS$-TL    FW-JJ-TL      VBZ-HL      VB+PPO      NPS-TL         NR$       TO-HL       FW-JJ       RB-HL        BER*     WDT+BEZ    FW-AT-TL     PPS+HVZ         HV*       JJ-NC       IN-NC       VB-NC       AP-HL       RB-TL    FW-IN-TL        NPS$      WRB-HL   FW-NNS-TL      PP$-TL       AT-NC      NN+BEZ       FW-RB     PPSS-NC      BEZ-HL      WDT-HL       MD-HL       FW-CC       FW-VB    JJ-TL-HL       RB-NC       ---HL      NNS-NC       CS-HL      NP+BEZ     PPSS-HL       FW-AT        BED*        HVZ*        :-TL     WPS+BEZ      JJS-TL      NN$-HL      PPS-HL       AP-TL FW-IN+AT-TL      JJR-HL      VBZ-TL    CD-TL-HL      VBG+TO      FW-WDT      DOZ-HL         NRS        .-NC      VBG-NC       UH-TL      JJR-TL       NP-NC       RP-HL   NNS-TL-HL    FW-CC-TL       BE-HL      PPO-TL FW-AT+NN-TL       TO-NC      PP$-NC      WPS-TL      FW-VBN      BER-HL      RB+BEZ      NR$-TL     WRB+BEZ       HV-NC      VBD-NC       NR-HL       TO-TL      PP$-HL         AP$         RB$          RN      FW-PPL     PPSS-TL       DT-TL      WRB-TL      FW-NN$      PPS-NC      VBN-NC      PPO-NC        BEM*      VBD-HL      NPS-HL       OD-HL       MD-TL        *-HL      NP$-HL      BEZ-TL      WPS+MD       FW-UH     BEDZ-NC    NP-TL-HL       MD+HV       FW-CD      ABN-TL       FW-NP      FW-VBG       DT-NC      WRB-NC      WDT-NC      VBZ-NC      PN+BEZ   VBN-TL-HL       DT-HL      JJT-HL      VBD-TL      DTI-HL      BER-TL       QL-TL        FW-*    IN-TL-HL      PPS-TL    FW-NN-NC     FW-PPSS     WPS+HVD      NP+HVZ     WRB+DOD         DT$    FW-IN+NN         CD$      JJR-NC      PPO-HL       DO-TL      WQL-TL       PN-TL    NR-TL-HL    AT-TL-HL      NN+HVZ      VBN+TO      BER-NC       UH-NC        ,-NC       CD-NC       RP-NC       CC-NC       CS-NC      BEZ-NC      ABN-HL       DO-HL     NNS$-HL      WPO-TL      FW-VBZ      FW-PPO       QL-HL    FW-OD-TL      HVZ-TL       RP-TL        ,-TL   FW-NN$-TL      FW-BEZ    FW-NP-TL      JJT-TL       EX+MD    FW-IN+AT       NR-NC       VB+TO       RP+IN      PN+HVZ    FW-VB-NC     NPS$-TL  WRB+BEZ-TL  FW-IN+AT-T    FW-RB-TL       HV-HL       VB+IN      DO*-HL      FW-PP$      FW-BER    FW-NR-TL       FW-CS       HV-TL   FW-PPO+IN   VBN-TL-NC   NNS-TL-NC    NN-TL-NC      BED-NC  PPS+BEZ-NC   NP+BEZ-NC      WPS-NC      EX+HVD       PN+MD       DT+MD       HV+TO       RB+CS       FW-DT       PN-HL FW-IN+NN-TL FW-AT+NP-TL      BEN-TL       CS-TL    CC-TL-HL    FW-JJ-NC      FW-VBD     FW-*-TL      DTS-HL       PN-NC     WDT+HVZ FW-IN+NP-TL       NN+MD   FW-NNS-NC       VB+RP   FW-PP$-TL      DTI-TL        .-TL      FW-NPS    FW-CD-TL  FW-PPL+VBZ      DOZ-TL  WDT+BEZ-NC      HVZ-NC       QL-NC  WPS+BEZ-NC  PPSS+MD-NC       AP-NC       DO-NC       MD-NC     NNS$-NC      PPL-NC      BEM-NC      NPS-NC    JJ+JJ-NC      WPS-HL   FW-DT+BEZ     WPS+HVZ       MD+TO   NN+BEZ-TL      EX+HVZ     PPSS+VB      NNS+MD       NP+MD       TO+VB       VB+AT     DTS+BEZ      MD*-HL     BEDZ-HL  PPS+BEZ-HL      HVD-HL    FW-AT-HL   FW-PP$-NC     NPS$-HL       UH-HL  WDT+BEZ-HL      PPL-HL   FW-VBD-TL PPSS+BER-TL       BE-TL  PPSS+HV-TL     DOD*-TL  WDT+BEZ-TL      FW-JJR  WDT+BER+PP    FW-UH-NC   RB+BEZ-HL      JJS-HL      PPL-TL      JJR+CS      NRS-TL       FW-HV     DOZ*-TL   FW-NPS-TL        *-TL       FW-PN       FW-BE      FW-PPS       FW-NR    FW-TO+VB      JJ$-TL    FW-VB-TL    FW-RB+CC      FW-WPO FW-NN-TL-NC      FW-WPS      FW-DTS  NNS$-TL-HL   FW-VBG-TL       EX-HL  PPSS+BER-N   NP+HVZ-NC   DT+BEZ-NC   RB+BEZ-NC        *-NC       EX-NC     BER*-NC PPSS+BER-NC      RBR-NC       OD-NC      ABN-NC      JJT-NC      DOD-NC      WPO-NC    NN+NN-NC    AP+AP-NC    VB+JJ-NC    VB+VB-NC       FW-QL    JJ-TL-NC      FW-JJT  WPS+BEZ-TL      HVG-HL     MD+PPSS       NR+MD       NN+IN   NN+HVD-TL     WDT+DOD      WRB+DO      WRB+IN      WRB+MD   NN+HVZ-TL     WRB+BER    PPSS+BEZ   PPSS+BEZ*      RBR+CS      IN+PPO       IN+IN     DO+PPSS     WRB+DOZ  WDT+DO+PPS    WRB+DOD*     WDT+BER    FW-OD-NC  FW-PPSS+HV      PN+HVD    FW-UH-TL \n",
            "     152470      120557       97958       64028       60638       58156       55110       37718       36464       34476       33693       29186       26167       22143       18253       17893       16872       14918       13802       13510       13372       12431       11181       10066        9806        9522        8957        8837        8789        8735        7373        6360        6009        5539        4895        4603        4509        4379        4107        4019        3928        3924        3405        3282        3010        2921        2573        2565        2470        2435        2433        2273        2264        2226        2164        1958        1935        1566        1558        1480        1477        1471        1353        1275        1233        1182        1047        1005         898         866         746         730         686         609         608         598         591         517         508         485         484         467         444         430         402         396         361         359         357         345         332         317         309         307         288         281         280         278         270         261         257         252         241         237         226         201         184         179         176         171         170         164         162         157         154         146         144         141         138         137         133         129         125         119         118         117         105         104         101          99          96          89          89          84          83          83          83          74          74          72          71          67          66          55          53          49          47          47          44          43          42          41          41          41          40          40          40          38          36          36          35          35          34          32          31          30          30          27          27          26          26          26          26          26          25          25          25          24          22          22          22          21          20          20          19          18          18          17          17          17          17          16          16          16          16          16          15          15          15          14          14          14          13          13          13          13          13          12          12          11          11          11          11          11          11          10          10          10           9           9           9           9           9           9           9           9           9           9           9           9           8           8           8           8           8           8           8           8           8           8           7           7           7           7           7           7           7           7           7           7           7           6           6           6           6           6           6           6           6           6           6           6           6           6           6           6           5           5           5           5           5           5           5           5           5           5           5           5           5           5           5           5           5           5           5           5           4           4           4           4           4           4           4           4           4           4           4           4           4           4           4           4           4           4           4           4           3           3           3           3           3           3           3           3           3           3           3           3           3           3           3           3           3           3           3           3           3           3           3           3           3           3           3           2           2           2           2           2           2           2           2           2           2           2           2           2           2           2           2           2           2           2           2           2           2           2           2           2           2           2           2           2           2           2           2           2           2           2           2           2           2           2           2           2           2           2           2           2           2           2           2           2           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1           1 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgXo14RgUhkB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_labels = len(set(tags))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oftNRdVTUMpF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "50d1721e-9f52-4701-fdc2-a4acd298fac9"
      },
      "source": [
        "print(num_labels)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "472\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKwYxg5fAQ7R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2b7d35fd-00ba-4b5f-8cb5-822ebbdd595c"
      },
      "source": [
        "vocabulary_size = 2000\n",
        "usage_tag_words = tag_words[:vocabulary_size]\n",
        "size = int(vocabulary_size * 0.75)\n",
        "print(size)\n",
        "train_words = usage_tag_words[:size]\n",
        "test_words = usage_tag_words[size:]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlVfBBbZB53J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for item in train_sents:\n",
        "  print(item)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuR-0_STPgJV",
        "colab_type": "text"
      },
      "source": [
        "### 2.5 Build the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MH3vN8eA3ra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Embedding, Activation, Flatten\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import collections"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sTNYu9yBMMi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_tag_vocabulary(tagged_words):\n",
        "  tag2id = {}\n",
        "  for item in tagged_words:\n",
        "    tag = item[1]\n",
        "    tag2id.setdefault(tag, len(tag2id))\n",
        "  return tag2id\n",
        "\n",
        "word2id = {k:v.index for k,v in word_vectors.vocab.items()}\n",
        "tag2id = get_tag_vocabulary(train_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flVlOOdDBj0c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bdf672dc-62e7-4afb-8cc0-623d18c6788f"
      },
      "source": [
        "def get_int_data(tagged_words, word2id, tag2id):\n",
        "  X, Y = [], [] # X for word ids, Y for tags\n",
        "  unk_count = 0\n",
        "\n",
        "  for word, tag in tagged_words:\n",
        "    Y.append(tag2id.get(tag))\n",
        "    if word in word2id:\n",
        "      X.append(word2id.get(word))\n",
        "    else:\n",
        "      X.append(UNK_INDEX)\n",
        "      unk_count += 1\n",
        "  print(\"Data created. Percentage of unknown words: %.3f\" % (unk_count/len(tagged_words)))\n",
        "  return np.array(X), np.array(Y)\n",
        "\n",
        "X_train, Y_train = get_int_data(train_words, word2id, tag2id)\n",
        "X_test, Y_test = get_int_data(test_words, word2id, tag2id)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data created. Percentage of unknown words: 0.047\n",
            "Data created. Percentage of unknown words: 0.034\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31IrMIY1NE0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# One-hot encoding\n",
        "Y_train, Y_test = to_categorical(Y_train), to_categorical(Y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOTBlEgnNoDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_new_word(new_word, new_vector, new_index, embedding_matrix, word2id):\n",
        "  embedding_matrix = np.insert(embedding_matrix, [new_index], [new_vector], axis = 0)\n",
        "\n",
        "  word2id = {word:(index + 1) if index >= new_index else index\n",
        "             for word, index in word2id.items()}\n",
        "  word2id[new_word] = new_index\n",
        "\n",
        "  return embedding_matrix, word2id\n",
        "\n",
        "embedding_matrix = word_vectors.vectors\n",
        "unk_vector = embedding_matrix.mean(0)\n",
        "embedding_matrix, word2id = add_new_word(UNK_TOKEN, unk_vector,\n",
        "                                         UNK_INDEX, embedding_matrix, word2id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhTACMwXAyso",
        "colab_type": "text"
      },
      "source": [
        "## Part 3. Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haNU6kVhPSQv",
        "colab_type": "text"
      },
      "source": [
        "### 3.1 Define the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-NecwYGOvUT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "91e556ff-0052-4167-ef0c-1103e2e420e0"
      },
      "source": [
        "def init_model(embedding_matrix, class_count):\n",
        "  vocab_length = len(embedding_matrix)\n",
        "  weights = [embedding_matrix]\n",
        "  bias = tf.Variable(tf.zeros([num_labels]))\n",
        "  #logits = tf.matmul(X_train, weights) + bias\n",
        "  #sce_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
        "  #    labels = Y_train, logits = logits))\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Embedding(input_dim=vocab_length,\n",
        "                      output_dim=EMB_DIM,\n",
        "                      weights=weights,\n",
        "                      input_length=1))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(HIDDEN_SIZE))\n",
        "  model.add(Activation(\"tanh\"))\n",
        "  model.add(Dense(class_count))\n",
        "  model.add(Activation(\"softmax\"))\n",
        "\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                loss=\"sparse_categorical_crossentropy\",\n",
        "                metrics=[\"accuracy\"])\n",
        "  return model\n",
        "\n",
        "pos_model = init_model(embedding_matrix, len(tag2id))\n",
        "pos_model.summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 1, 300)            4552200   \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 50)                15050     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 428)               21828     \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 428)               0         \n",
            "=================================================================\n",
            "Total params: 4,589,078\n",
            "Trainable params: 4,589,078\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5h4nPccYEMY",
        "colab_type": "text"
      },
      "source": [
        "### 3.2 Train the Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMlAdEIWWSWn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "410560ae-eac7-4db2-9f2f-ffcea08f8c08"
      },
      "source": [
        "pos_model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=50, verbose=1)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1500 samples\n",
            "Epoch 1/50\n",
            "1500/1500 [==============================] - 1s 697us/sample - loss: 6.4958 - accuracy: 0.0767\n",
            "Epoch 2/50\n",
            "1500/1500 [==============================] - 1s 618us/sample - loss: 4.5856 - accuracy: 0.1267\n",
            "Epoch 3/50\n",
            "1500/1500 [==============================] - 1s 654us/sample - loss: 3.0370 - accuracy: 0.2260\n",
            "Epoch 4/50\n",
            "1500/1500 [==============================] - 1s 626us/sample - loss: 2.2347 - accuracy: 0.4240\n",
            "Epoch 5/50\n",
            "1500/1500 [==============================] - 1s 621us/sample - loss: 1.7745 - accuracy: 0.5387\n",
            "Epoch 6/50\n",
            "1500/1500 [==============================] - 1s 607us/sample - loss: 1.4932 - accuracy: 0.5927\n",
            "Epoch 7/50\n",
            "1500/1500 [==============================] - 1s 607us/sample - loss: 1.2905 - accuracy: 0.6633\n",
            "Epoch 8/50\n",
            "1500/1500 [==============================] - 1s 611us/sample - loss: 1.1446 - accuracy: 0.7153\n",
            "Epoch 9/50\n",
            "1500/1500 [==============================] - 1s 598us/sample - loss: 1.0247 - accuracy: 0.7527\n",
            "Epoch 10/50\n",
            "1500/1500 [==============================] - 1s 606us/sample - loss: 0.9315 - accuracy: 0.7820\n",
            "Epoch 11/50\n",
            "1500/1500 [==============================] - 1s 606us/sample - loss: 0.8555 - accuracy: 0.8100\n",
            "Epoch 12/50\n",
            "1500/1500 [==============================] - 1s 601us/sample - loss: 0.7911 - accuracy: 0.8253\n",
            "Epoch 13/50\n",
            "1500/1500 [==============================] - 1s 605us/sample - loss: 0.7367 - accuracy: 0.8333\n",
            "Epoch 14/50\n",
            "1500/1500 [==============================] - 1s 598us/sample - loss: 0.6908 - accuracy: 0.8540\n",
            "Epoch 15/50\n",
            "1500/1500 [==============================] - 1s 631us/sample - loss: 0.6500 - accuracy: 0.8627\n",
            "Epoch 16/50\n",
            "1500/1500 [==============================] - 1s 556us/sample - loss: 0.6151 - accuracy: 0.8687\n",
            "Epoch 17/50\n",
            "1500/1500 [==============================] - 1s 548us/sample - loss: 0.5842 - accuracy: 0.8767\n",
            "Epoch 18/50\n",
            "1500/1500 [==============================] - 1s 598us/sample - loss: 0.5573 - accuracy: 0.8820\n",
            "Epoch 19/50\n",
            "1500/1500 [==============================] - 1s 608us/sample - loss: 0.5320 - accuracy: 0.8873\n",
            "Epoch 20/50\n",
            "1500/1500 [==============================] - 1s 594us/sample - loss: 0.5106 - accuracy: 0.8927\n",
            "Epoch 21/50\n",
            "1500/1500 [==============================] - 1s 584us/sample - loss: 0.4921 - accuracy: 0.8967\n",
            "Epoch 22/50\n",
            "1500/1500 [==============================] - 1s 596us/sample - loss: 0.4737 - accuracy: 0.9000\n",
            "Epoch 23/50\n",
            "1500/1500 [==============================] - 1s 604us/sample - loss: 0.4577 - accuracy: 0.9033\n",
            "Epoch 24/50\n",
            "1500/1500 [==============================] - 1s 596us/sample - loss: 0.4416 - accuracy: 0.9053\n",
            "Epoch 25/50\n",
            "1500/1500 [==============================] - 1s 610us/sample - loss: 0.4289 - accuracy: 0.9073\n",
            "Epoch 26/50\n",
            "1500/1500 [==============================] - 1s 585us/sample - loss: 0.4167 - accuracy: 0.9087\n",
            "Epoch 27/50\n",
            "1500/1500 [==============================] - 1s 579us/sample - loss: 0.4060 - accuracy: 0.9120\n",
            "Epoch 28/50\n",
            "1500/1500 [==============================] - 1s 627us/sample - loss: 0.3958 - accuracy: 0.9147\n",
            "Epoch 29/50\n",
            "1500/1500 [==============================] - 1s 650us/sample - loss: 0.3867 - accuracy: 0.9160\n",
            "Epoch 30/50\n",
            "1500/1500 [==============================] - 1s 628us/sample - loss: 0.3775 - accuracy: 0.9167\n",
            "Epoch 31/50\n",
            "1500/1500 [==============================] - 1s 605us/sample - loss: 0.3699 - accuracy: 0.9173\n",
            "Epoch 32/50\n",
            "1500/1500 [==============================] - 1s 616us/sample - loss: 0.3621 - accuracy: 0.9173\n",
            "Epoch 33/50\n",
            "1500/1500 [==============================] - 1s 609us/sample - loss: 0.3553 - accuracy: 0.9200\n",
            "Epoch 34/50\n",
            "1500/1500 [==============================] - 1s 548us/sample - loss: 0.3494 - accuracy: 0.9213\n",
            "Epoch 35/50\n",
            "1500/1500 [==============================] - 1s 569us/sample - loss: 0.3427 - accuracy: 0.9233\n",
            "Epoch 36/50\n",
            "1500/1500 [==============================] - 1s 605us/sample - loss: 0.3374 - accuracy: 0.9227\n",
            "Epoch 37/50\n",
            "1500/1500 [==============================] - 1s 595us/sample - loss: 0.3318 - accuracy: 0.9260\n",
            "Epoch 38/50\n",
            "1500/1500 [==============================] - 1s 635us/sample - loss: 0.3275 - accuracy: 0.9267\n",
            "Epoch 39/50\n",
            "1500/1500 [==============================] - 1s 598us/sample - loss: 0.3232 - accuracy: 0.9267\n",
            "Epoch 40/50\n",
            "1500/1500 [==============================] - 1s 607us/sample - loss: 0.3184 - accuracy: 0.9267\n",
            "Epoch 41/50\n",
            "1500/1500 [==============================] - 1s 546us/sample - loss: 0.3148 - accuracy: 0.9267\n",
            "Epoch 42/50\n",
            "1500/1500 [==============================] - 1s 529us/sample - loss: 0.3116 - accuracy: 0.9273\n",
            "Epoch 43/50\n",
            "1500/1500 [==============================] - 1s 574us/sample - loss: 0.3086 - accuracy: 0.9287\n",
            "Epoch 44/50\n",
            "1500/1500 [==============================] - 1s 600us/sample - loss: 0.3054 - accuracy: 0.9287\n",
            "Epoch 45/50\n",
            "1500/1500 [==============================] - 1s 616us/sample - loss: 0.3023 - accuracy: 0.9287\n",
            "Epoch 46/50\n",
            "1500/1500 [==============================] - 1s 617us/sample - loss: 0.2999 - accuracy: 0.9280\n",
            "Epoch 47/50\n",
            "1500/1500 [==============================] - 1s 609us/sample - loss: 0.2982 - accuracy: 0.9287\n",
            "Epoch 48/50\n",
            "1500/1500 [==============================] - 1s 598us/sample - loss: 0.2956 - accuracy: 0.9253\n",
            "Epoch 49/50\n",
            "1500/1500 [==============================] - 1s 602us/sample - loss: 0.2942 - accuracy: 0.9287\n",
            "Epoch 50/50\n",
            "1500/1500 [==============================] - 1s 622us/sample - loss: 0.2918 - accuracy: 0.9280\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2cabb8fcf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmeU6LWcXwZ_",
        "colab_type": "text"
      },
      "source": [
        "After 50 epochs of training, the accuracy has been improved from 7.67% to 92.8%"
      ]
    }
  ]
}